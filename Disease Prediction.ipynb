{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df0128a-8528-42ef-88e2-9ccace922385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Enhanced Disease Prediction Model ===\n",
      "\n",
      "Training data: (4920, 134)\n",
      "Test data: (42, 133)\n",
      "\n",
      "=== Data Quality Analysis ===\n",
      "\n",
      "Disease distribution in training data:\n",
      "prognosis\n",
      "Fungal infection                           120\n",
      "Hepatitis C                                120\n",
      "Hepatitis E                                120\n",
      "Alcoholic hepatitis                        120\n",
      "Tuberculosis                               120\n",
      "Common Cold                                120\n",
      "Pneumonia                                  120\n",
      "Dimorphic hemmorhoids(piles)               120\n",
      "Heart attack                               120\n",
      "Varicose veins                             120\n",
      "Hypothyroidism                             120\n",
      "Hyperthyroidism                            120\n",
      "Hypoglycemia                               120\n",
      "Osteoarthristis                            120\n",
      "Arthritis                                  120\n",
      "(vertigo) Paroymsal  Positional Vertigo    120\n",
      "Acne                                       120\n",
      "Urinary tract infection                    120\n",
      "Psoriasis                                  120\n",
      "Hepatitis D                                120\n",
      "Hepatitis B                                120\n",
      "Allergy                                    120\n",
      "hepatitis A                                120\n",
      "GERD                                       120\n",
      "Chronic cholestasis                        120\n",
      "Drug Reaction                              120\n",
      "Peptic ulcer diseae                        120\n",
      "AIDS                                       120\n",
      "Diabetes                                   120\n",
      "Gastroenteritis                            120\n",
      "Bronchial Asthma                           120\n",
      "Hypertension                               120\n",
      "Migraine                                   120\n",
      "Cervical spondylosis                       120\n",
      "Paralysis (brain hemorrhage)               120\n",
      "Jaundice                                   120\n",
      "Malaria                                    120\n",
      "Chicken pox                                120\n",
      "Dengue                                     120\n",
      "Typhoid                                    120\n",
      "Impetigo                                   120\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Feature Engineering ===\n",
      "\n",
      "Most common symptoms:\n",
      "fatigue              1932\n",
      "vomiting             1914\n",
      "high_fever           1362\n",
      "loss_of_appetite     1152\n",
      "nausea               1146\n",
      "headache             1134\n",
      "abdominal_pain       1032\n",
      "yellowish_skin        912\n",
      "yellowing_of_eyes     816\n",
      "chills                798\n",
      "dtype: int64\n",
      "\n",
      "Removing 0 too common symptoms\n",
      "Removing 1 too rare symptoms\n",
      "Features after cleaning: 128\n",
      "\n",
      "Number of classes: 41\n",
      "Final feature count: 128\n",
      "\n",
      "=== Enhanced Feature Selection ===\n",
      "Selected 50 features\n",
      "\n",
      "=== Improved Model Training ===\n",
      "\n",
      "=== Model Evaluation ===\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  CV Score: 0.9829 (+/- 0.0315)\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting:\n",
      "  Accuracy: 0.9762\n",
      "  Precision: 0.9881\n",
      "  Recall: 0.9762\n",
      "  F1-Score: 0.9762\n",
      "  CV Score: 0.9829 (+/- 0.0315)\n",
      "\n",
      "Training SVM...\n",
      "SVM:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  CV Score: 0.9829 (+/- 0.0315)\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  CV Score: 0.9829 (+/- 0.0315)\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  CV Score: 0.9829 (+/- 0.0315)\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree:\n",
      "  Accuracy: 0.4048\n",
      "  Precision: 0.3819\n",
      "  Recall: 0.4048\n",
      "  F1-Score: 0.3827\n",
      "  CV Score: 0.4187 (+/- 0.0333)\n",
      "\n",
      "============================================================\n",
      "FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "                     accuracy  precision  recall      f1  cv_mean  cv_std\n",
      "Random Forest          1.0000     1.0000  1.0000  1.0000   0.9829  0.0157\n",
      "Gradient Boosting      0.9762     0.9881  0.9762  0.9762   0.9829  0.0157\n",
      "SVM                    1.0000     1.0000  1.0000  1.0000   0.9829  0.0157\n",
      "Logistic Regression    1.0000     1.0000  1.0000  1.0000   0.9829  0.0157\n",
      "K-Nearest Neighbors    1.0000     1.0000  1.0000  1.0000   0.9829  0.0157\n",
      "Decision Tree          0.4048     0.3819  0.4048  0.3827   0.4187  0.0166\n",
      "\n",
      "üéØ BEST MODEL: Random Forest\n",
      "\n",
      "=== Prediction Validation ===\n",
      "\n",
      "=== Testing Sample Predictions ===\n",
      "\n",
      "üß™ Testing: Common Cold\n",
      "  Note: Symptom 'runny_nose' not in selected features\n",
      "  Note: Symptom 'sneezing' not in selected features\n",
      "\n",
      "üîç Prediction Analysis:\n",
      "Top prediction: Allergy (confidence: 35.53%)\n",
      "‚ö†Ô∏è  LOW CONFIDENCE: Below threshold (70%)\n",
      "Considered predictions:\n",
      "  - Allergy: 35.53%\n",
      "  - Urinary tract infection: 9.54%\n",
      "  - AIDS: 6.53%\n",
      "‚úÖ Final prediction: Low confidence - consult healthcare professional (Confidence: 35.53%)\n",
      "\n",
      "üß™ Testing: UTI Test\n",
      "  Note: Symptom 'burning_micturition' not in selected features\n",
      "  Note: Symptom 'bladder_discomfort' not in selected features\n",
      "‚ùå No valid symptoms for prediction\n",
      "\n",
      "üß™ Testing: Fever Test\n",
      "\n",
      "üîç Prediction Analysis:\n",
      "Top prediction: AIDS (confidence: 31.97%)\n",
      "‚ö†Ô∏è  LOW CONFIDENCE: Below threshold (70%)\n",
      "Considered predictions:\n",
      "  - AIDS: 31.97%\n",
      "  - Impetigo: 9.94%\n",
      "  - Urinary tract infection: 9.40%\n",
      "‚úÖ Final prediction: Low confidence - consult healthcare professional (Confidence: 31.97%)\n",
      "\n",
      "=== Feature Importance Analysis ===\n",
      "\n",
      "Top 10 most important features:\n",
      "              feature  importance\n",
      "14         high_fever    0.050093\n",
      "4          joint_pain    0.032670\n",
      "21             nausea    0.031695\n",
      "45        muscle_pain    0.029629\n",
      "0             itching    0.029041\n",
      "26          diarrhoea    0.027621\n",
      "28  yellowing_of_eyes    0.027436\n",
      "33         chest_pain    0.026404\n",
      "7            vomiting    0.026399\n",
      "22   loss_of_appetite    0.026184\n",
      "\n",
      "============================================================\n",
      "MODEL READY FOR USE\n",
      "============================================================\n",
      "‚úÖ Enhanced with:\n",
      "   - Better feature selection\n",
      "   - Confidence thresholding\n",
      "   - Multiple metric evaluation\n",
      "   - Prediction validation\n",
      "   - Cross-validation\n",
      "\n",
      "‚ö†Ô∏è  REMEMBER: This is for educational purposes only!\n",
      "   Always consult healthcare professionals for medical advice.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. IMPROVED DATA LOADING AND VALIDATION\n",
    "print(\"=== Enhanced Disease Prediction Model ===\\n\")\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv(r\"C:\\Users\\mysel\\Downloads\\archive\\Training.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\mysel\\Downloads\\archive\\Testing.csv\")\n",
    "\n",
    "print(f\"Training data: {df_train.shape}\")\n",
    "print(f\"Test data: {df_test.shape}\")\n",
    "\n",
    "# Remove unnecessary column\n",
    "df_train = df_train.drop(columns=['Unnamed: 133'], errors='ignore')\n",
    "\n",
    "# 2. DATA QUALITY CHECKS\n",
    "print(\"\\n=== Data Quality Analysis ===\")\n",
    "\n",
    "# Check disease distribution\n",
    "disease_counts = df_train['prognosis'].value_counts()\n",
    "print(\"\\nDisease distribution in training data:\")\n",
    "print(disease_counts)\n",
    "\n",
    "# Check if any disease has too few samples\n",
    "rare_diseases = disease_counts[disease_counts < 10]\n",
    "if len(rare_diseases) > 0:\n",
    "    print(f\"\\nRare diseases (<10 samples): {len(rare_diseases)}\")\n",
    "    print(rare_diseases)\n",
    "\n",
    "# 3. ENHANCED FEATURE ENGINEERING\n",
    "print(\"\\n=== Feature Engineering ===\")\n",
    "\n",
    "# Analyze symptom frequency\n",
    "symptom_frequency = df_train.drop('prognosis', axis=1).sum().sort_values(ascending=False)\n",
    "print(f\"\\nMost common symptoms:\")\n",
    "print(symptom_frequency.head(10))\n",
    "\n",
    "# Remove overly common/rare symptoms (potential noise)\n",
    "common_threshold = len(df_train) * 0.8  # Symptoms in >80% of cases\n",
    "rare_threshold = len(df_train) * 0.01   # Symptoms in <1% of cases\n",
    "\n",
    "too_common = symptom_frequency[symptom_frequency > common_threshold].index\n",
    "too_rare = symptom_frequency[symptom_frequency < rare_threshold].index\n",
    "\n",
    "print(f\"\\nRemoving {len(too_common)} too common symptoms\")\n",
    "print(f\"Removing {len(too_rare)} too rare symptoms\")\n",
    "\n",
    "columns_to_drop = list(too_common) + list(too_rare) + ['yellow_crust_ooze', 'red_sore_around_nose', 'blister']\n",
    "df_train_clean = df_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "df_test_clean = df_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"Features after cleaning: {df_train_clean.shape[1] - 1}\")\n",
    "\n",
    "# 4. PREPARE DATA WITH BETTER VALIDATION\n",
    "X_train = df_train_clean.drop('prognosis', axis=1)\n",
    "y_train = df_train_clean['prognosis']\n",
    "X_test = df_test_clean.drop('prognosis', axis=1)\n",
    "y_test = df_test_clean['prognosis']\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "print(f\"\\nNumber of classes: {len(le.classes_)}\")\n",
    "print(f\"Final feature count: {X_train.shape[1]}\")\n",
    "\n",
    "# 5. IMPROVED FEATURE SELECTION\n",
    "print(\"\\n=== Enhanced Feature Selection ===\")\n",
    "\n",
    "# Use fewer but more meaningful features\n",
    "k_features = min(50, X_train.shape[1])  # Reduced from 80\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train_encoded)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(f\"Selected {len(selected_features)} features\")\n",
    "\n",
    "# 6. ENHANCED MODEL TRAINING WITH BETTER PARAMETERS\n",
    "print(\"\\n=== Improved Model Training ===\")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_train_encoded), \n",
    "    y=y_train_encoded\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Updated models with better parameters\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200, \n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        class_weight=class_weight_dict, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        class_weight='balanced', \n",
    "        probability=True,  # Enable probability for confidence scores\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        class_weight='balanced', \n",
    "        random_state=42,\n",
    "        C=0.1  # More regularization\n",
    "    ),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        weights='distance'\n",
    "    ),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        class_weight=class_weight_dict, \n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# 7. COMPREHENSIVE MODEL EVALUATION\n",
    "print(\"\\n=== Model Evaluation ===\\n\")\n",
    "\n",
    "results = {}\n",
    "detailed_reports = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Cross-validation for better evaluation\n",
    "    cv_scores = cross_val_score(model, X_train_selected, y_train_encoded, cv=5)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_selected, y_train_encoded)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    y_pred_proba = model.predict_proba(X_test_selected) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    precision = precision_score(y_test_encoded, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_encoded, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_encoded, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print()\n",
    "\n",
    "# 8. MODEL COMPARISON\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + comparison_df.round(4).to_string())\n",
    "\n",
    "# Select best model based on multiple metrics\n",
    "best_model_name = comparison_df['f1'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nüéØ BEST MODEL: {best_model_name}\")\n",
    "\n",
    "# 9. PREDICTION VALIDATION SYSTEM\n",
    "print(\"\\n=== Prediction Validation ===\")\n",
    "\n",
    "def validate_prediction(model, symptoms, feature_names, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Enhanced prediction with confidence checking and validation\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'predict_proba'):\n",
    "        return \"Model does not support probability predictions\", 0.0\n",
    "    \n",
    "    probabilities = model.predict_proba([symptoms])[0]\n",
    "    max_prob = probabilities.max()\n",
    "    predicted_class = model.classes_[probabilities.argmax()]\n",
    "    predicted_disease = le.inverse_transform([predicted_class])[0]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_3_indices = probabilities.argsort()[-3:][::-1]\n",
    "    top_predictions = [\n",
    "        (le.inverse_transform([idx])[0], prob) \n",
    "        for idx, prob in zip(top_3_indices, probabilities[top_3_indices])\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüîç Prediction Analysis:\")\n",
    "    print(f\"Top prediction: {predicted_disease} (confidence: {max_prob:.2%})\")\n",
    "    \n",
    "    if max_prob < threshold:\n",
    "        print(f\"‚ö†Ô∏è  LOW CONFIDENCE: Below threshold ({threshold:.0%})\")\n",
    "        print(\"Considered predictions:\")\n",
    "        for disease, conf in top_predictions:\n",
    "            print(f\"  - {disease}: {conf:.2%}\")\n",
    "        return \"Low confidence - consult healthcare professional\", max_prob\n",
    "    \n",
    "    # Check if symptoms make sense for the prediction\n",
    "    active_symptoms = [feature_names[i] for i, val in enumerate(symptoms) if val == 1]\n",
    "    print(f\"Active symptoms: {', '.join(active_symptoms)}\")\n",
    "    \n",
    "    return predicted_disease, max_prob\n",
    "\n",
    "# 10. TEST WITH SAMPLE SYMPTOMS\n",
    "print(\"\\n=== Testing Sample Predictions ===\")\n",
    "\n",
    "# Test cases with realistic symptom combinations\n",
    "test_cases = [\n",
    "    {'name': 'Common Cold', 'symptoms': ['runny_nose', 'sneezing', 'chills']},\n",
    "    {'name': 'UTI Test', 'symptoms': ['burning_micturition', 'bladder_discomfort']},\n",
    "    {'name': 'Fever Test', 'symptoms': ['high_fever']},\n",
    "]\n",
    "\n",
    "for test_case in test_cases:\n",
    "    print(f\"\\nüß™ Testing: {test_case['name']}\")\n",
    "    \n",
    "    # Create symptom vector\n",
    "    symptom_vector = [0] * len(selected_features)\n",
    "    active_count = 0\n",
    "    \n",
    "    for symptom in test_case['symptoms']:\n",
    "        if symptom in selected_features:\n",
    "            idx = list(selected_features).index(symptom)\n",
    "            symptom_vector[idx] = 1\n",
    "            active_count += 1\n",
    "        else:\n",
    "            print(f\"  Note: Symptom '{symptom}' not in selected features\")\n",
    "    \n",
    "    if active_count > 0:\n",
    "        prediction, confidence = validate_prediction(\n",
    "            best_model, symptom_vector, selected_features, threshold=0.7\n",
    "        )\n",
    "        print(f\"‚úÖ Final prediction: {prediction} (Confidence: {confidence:.2%})\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid symptoms for prediction\")\n",
    "\n",
    "# 11. FEATURE IMPORTANCE ANALYSIS\n",
    "print(\"\\n=== Feature Importance Analysis ===\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    print(feature_importance_df.head(10))\n",
    "    \n",
    "    # Check if any features are dominating\n",
    "    top_feature_ratio = feature_importance_df['importance'].iloc[0] / feature_importance_df['importance'].sum()\n",
    "    if top_feature_ratio > 0.3:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Top feature has {top_feature_ratio:.1%} of total importance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL READY FOR USE\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Enhanced with:\")\n",
    "print(\"   - Better feature selection\")\n",
    "print(\"   - Confidence thresholding\")\n",
    "print(\"   - Multiple metric evaluation\")\n",
    "print(\"   - Prediction validation\")\n",
    "print(\"   - Cross-validation\")\n",
    "print(\"\\n‚ö†Ô∏è  REMEMBER: This is for educational purposes only!\")\n",
    "print(\"   Always consult healthcare professionals for medical advice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288c3d83-b3ad-48b4-a04d-3ccee6c5125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL SELECTION AND DEPLOYMENT\n",
      "============================================================\n",
      "ü§ñ AUTO-SELECTED BEST MODEL: Random Forest\n",
      "   F1-Score: 1.0000\n",
      "   Accuracy: 1.0000\n",
      "\n",
      "=== Creating Deployment Package ===\n",
      "‚úÖ Model package saved as 'disease_prediction_model.pkl'\n",
      "\n",
      "=== Verifying Saved Model ===\n",
      "‚úÖ Model loaded: Random Forest\n",
      "‚úÖ Features: 50\n",
      "‚úÖ Classes: 41\n"
     ]
    }
   ],
   "source": [
    "# 12. SELECT AND SAVE THE BEST MODEL\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL SELECTION AND DEPLOYMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Option 1: Auto-select best model based on F1-score\n",
    "best_model_name = comparison_df['f1'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"ü§ñ AUTO-SELECTED BEST MODEL: {best_model_name}\")\n",
    "print(f\"   F1-Score: {comparison_df.loc[best_model_name]['f1']:.4f}\")\n",
    "print(f\"   Accuracy: {comparison_df.loc[best_model_name]['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 13. CREATE DEPLOYMENT PACKAGE\n",
    "print(\"\\n=== Creating Deployment Package ===\")\n",
    "\n",
    "# Save the model and necessary components\n",
    "import joblib\n",
    "\n",
    "deployment_package = {\n",
    "    'model': best_model,\n",
    "    'feature_selector': selector,\n",
    "    'label_encoder': le,\n",
    "    'selected_features': list(selected_features),\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'model_name': best_model_name,\n",
    "    'performance_metrics': comparison_df.loc[best_model_name].to_dict(),\n",
    "    'confidence_threshold': 0.7  # Default confidence threshold\n",
    "}\n",
    "\n",
    "# Save the deployment package\n",
    "joblib.dump(deployment_package, 'disease_prediction_model.pkl')\n",
    "print(\"‚úÖ Model package saved as 'disease_prediction_model.pkl'\")\n",
    "\n",
    "# 14. VERIFY THE SAVED MODEL\n",
    "print(\"\\n=== Verifying Saved Model ===\")\n",
    "\n",
    "# Load and test the saved model\n",
    "loaded_package = joblib.load('disease_prediction_model.pkl')\n",
    "loaded_model = loaded_package['model']\n",
    "loaded_features = loaded_package['selected_features']\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {loaded_package['model_name']}\")\n",
    "print(f\"‚úÖ Features: {len(loaded_features)}\")\n",
    "print(f\"‚úÖ Classes: {len(loaded_package['label_encoder'].classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e572b-8f14-46cb-b466-ada9247115ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
